model:
#  number_of_epochs: 5000
  number_of_epochs: 50
#  batch_size: 100
  batch_size: 10
  translation_hidden_size: 1000
  encoder_hidden_states: [1500, 1000, 500]
  decoder_hidden_states: [1000, 1500]
  discriminator_hidden_states: [1000]
  discriminator_dense_hidden_size: 500
#  learn_rate: 0.0001
  learn_rate: 0.0035
  dropout: 0.1
  discriminator_dropout: 0.1
  bidirectional_encoder: False
  bidirectional_discriminator: False
#  curriculum_training: True
  reconstruction_coefficient: 1.0
  semantic_distance_coefficient: 1.0
  discriminator_type: 'embedding'
#  discriminator_type: 'content'

embedding:
#  min_word_occurrences: 2
  min_word_occurrences: 0
#  word_size: 200
  word_size: 50
  should_train: True

loss:
#  upper_range: 5.0
#  lower_range: 3.0

sentence:
  limit: 300000
#  limit: 150
  min_length: 3
  max_length: 15
